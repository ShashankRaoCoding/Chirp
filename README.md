
# ğŸ¦ Chirp: Whisper with AI

**Chirp** is a sleek, transparent desktop overlay that provides a whisper-quiet interface for chatting with a local LLaMA 3 model via Ollama.

No browser tabs. No busy windows. Just a discreet, always-on-top assistant that listens when summoned and fades away when you're done.

---

## âœ¨ Features

+ ğŸ–¥ï¸ Transparent UI with no visible frame
+ ğŸ§  Connects to local LLaMA 3 model via Ollama
+ ğŸ“¡ Streams responses in real time
+ ğŸ“Œ Always-on-top, autohide when not in use
+ ğŸ–±ï¸ Reappears when the mouse approaches the bottom of the screen
+ âš™ï¸ Minimal configuration, easy to run
+ ğŸ“¦ Powered by [Astilectron](https://github.com/asticode/go-astilectron) + Go + HTML/CSS + Javascript 

---

## ğŸš€ Getting Started

### Prerequisites

+ [Go](https://go.dev/dl/)
+ [Ollama](https://ollama.com) installed and configured
+ LLaMA 3 model pulled via:

```bash
  ollama pull llama3
````

---

### ğŸ›  Build and Run

Double click on the main.exe file in the folder. Alternatively: 

```bash
go run main.go
```

Or to build:

```bash
go build -o chirp.exe
./chirp.exe
```

Chirp will:

1. Automatically start the `ollama serve` process in the background.
2. Launch a transparent always-on-top window.
3. Watch for your cursor to approach the screen bottom and slide into view.

---

## ğŸ“‚ Project Structure

| File / Folder     | Description                                                    |
| ----------------- | -------------------------------------------------------------- |
| `main.go`         | Main Go application with embedded HTTP server and chat routing |
| `pages/chat.html` | Your frontend chat interface                                   |
| `shankskit`       | Custom UI/bootstrapping package for Astilectron                |
| `go.mod`          | Module definition                                              |

---

## ğŸ§  How It Works

1. You send a prompt from the frontend.
2. Go backend sends it to Ollamaâ€™s local `/generate` API with streaming enabled.
3. Response tokens are streamed back to the UI live.

---

## ğŸ™Œ Credits

* Built using [Astilectron](https://github.com/asticode/go-astilectron)
* Local LLM served by [Ollama](https://ollama.com)
* Window auto-hide by monitoring Windows cursor position with syscall

---

## ğŸ§ª Future Features (Ideas)

* ğŸ”Š Voice-to-text input
* ğŸ’¬ Multi-chat memory
* ğŸ¨ Themed UI options
* ğŸ–¥ï¸ Screen-edge pinning for other sides
* ğŸ” Local encryption of chat history

---

## ğŸ› Known Issues

* Only tested on **Windows**
* Requires LLaMA model and Ollama to be working locally

---

## ğŸ“¬ Contact

Made with â¤ï¸ by [@shashankraocoding](https://github.com/shashankraocoding)
For questions or ideas, feel free to open an issue or PR!

---


---

### âš ï¸ Liabilities

Chirp is provided **as-is**, with no guarantees or warranties. By using this application, you acknowledge and accept the following:

* ğŸ§  **AI Output Responsibility**: The responses generated by the LLaMA model via Ollama are not moderated. You are solely responsible for interpreting and using the output.
* ğŸ›¡ï¸ **Data Privacy**: This app runs locally and does not transmit data externally. However, **you** are responsible for safeguarding any sensitive prompts or responses.
* âš ï¸ **Experimental Nature**: Chirp is an experimental interface for local AI interaction. It is not intended for critical, medical, legal, or safety-related use.
* ğŸ–¥ï¸ **Platform Limitations**: Chirp has only been tested on **Windows**. Behavior on other platforms is unverified and unsupported.
* ğŸ”§ **System Resources**: Running large language models locally can be resource-intensive. Monitor your system performance and usage while using this tool.

By using Chirp, you agree that the developers and contributors are **not liable** for any damages, data loss, or issues arising from its use, including as a result of negligence.

---

